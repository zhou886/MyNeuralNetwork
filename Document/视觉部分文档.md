# 计算机视觉部分文档

[toc]

## 问题概述

​	视觉部分的需求是从摄像机中读取图像，然后判断该图像中是否有人物出现。该人物必须面朝机器人且注视机器人，否则将被视作仅从机器人面前经过而非想要和机器人交互。

## 问题分析

​	本问题的核心是如何判断图像中的人物面朝机器人并且注视机器人，经过考虑本部分使用卷积神经网络来进行实现。

​	一开始我通过修改YOLOv5的代码，然后简单地调用接口api实现了上述功能。但是我觉得这没有意思，不能将自己所学的知识加以运用。于是我通过网上的视频教程学习了北京邮电大学鲁鹏副教授的研究生课程计算机视觉与深度学习，同时也通过另外一名up主的Pytorch视频教程学会了Pytorch的基本用法。计算机视觉与深度学习这门研究生课程的学习加深了我对神经网络的理解，并掌握了处理图像用的卷积神经网络的更多细节。

​	这些学习花费了我大概三周的时间，之后我又需要准备几门专业课的考试所以无暇开始这项工作，所以最后剩余给我调整超参数、训练模型、改进不足的时间所剩无几，但我仍希望能尽量达到更好的效果并进行了诸多的尝试。

## 模块功能概述

​	本模块运行在一个独立的进程中。模块的状态置为没有人出现并注视。

​	然后模块会从机器人的摄像机中读取图像，经由训练好的卷积神经网络判断图像中是否有人物出现并注视机器人。由于卷积神经网络并非能准确判断，所以引入假设检验来提高判断准确率。将判断的结果与现有的状态比较，若相同则不做任何处理，若不同则会修改状态并往公共消息队列中发送最新的状态。重复上述过程。

​	运行在其他进程中的其他模块会去读取公共消息队列并根据公共消息队列中的最新状态采取不同的行动。

![视觉模块流程图](.\视觉模块流程图.svg)



## 卷积神经网络的实现

### 收集数据并搭建数据集类

​	为了使网络有良好的表现，一共收集16,461张正视摄像头的人像图像用作识别正确的部分和5,468张室内场景图像用作识别错误的部分。

​	数据集结构为：

>dataset
>
>+ True
>  + img1
>  + img2
>  + ...
>+ False
>  + img1
>  + img2
>  + ...

​	通过继承Pytorch中的`Dateset`类构建自己的`dataset`类，命名为`MyDataset`。该数据集类把所有数据中的前80%划作训练集，后20%划作测试集。

​	同时`MyDataset`中还有`train`和`transform`两个参数，前者负责设置该`MyDataset`实例是作为训练集还是测试集，后者负责对从`MyDataset`实例中取出的图像做对应的变换。

### 搭建卷积神经网络

​	因为此次卷积神经网络的任务是一个二分类问题，任务本身比较简单，所以不设置较深较宽的网络结构。

​	网络结构采用如下设置：

1. 卷积层，输入通道数为3，输出通道数为32，卷积核大小为5x5，边缘采用0填充。
2. 最大值池化层，池化核为2x2。
3. 卷积层，输入通道数为32，输出通道数为32，卷积核大小为5x5，边缘采用0填充。
4. 最大值池化层，池化核为2x2。
5. 卷积层，输入通道数为32，输出通道数为64，卷积核大小为5x5，边缘采用0填充。
6. 最大值池化层，池化核为2x2。
7. Flatten层，将向量展平。
8. 全连接层，输入为4096维向量，输出为64维向量。
9. ReLU层，用作上层全连接层的激活函数。
10. 全连接层，输入为64维向量，输出为2维向量。

![卷积神经网络结构](.\卷积神经网络结构.svg)

​	其中卷积层的作用是提取图像中的各种有用的数据，通过多层卷积层后能够提取出图像中高维的信息。相比于直接使用不经任何处理的图像进行学习的网络，卷积神经网络能大幅提高网络训练的效率并减小网络的规模。

​	池化层的作用也是抽取数据，缩小数据规模的同时保留原数据中的主要特征。Pytorch中的池化层同时兼顾取最值和降采样的效果，取最值可以保留原数据中的主要特征，而降采样便于后面的卷积层提取出更高维的数据特征。

​	Flatten层的作用是将经过三层卷积层和三层池化层后的64x8x8的向量展开变成4096维向量。

​	全连接层相当于神经网络中的整合函数，负责对数据进行加权求和并加上偏置值。

​	ReLU层则是神经网络中的激活函数，其函数形式如下所示。
$$
f(x) = 
max(0, x) =
\left \{ 
\begin{array} \left
x  & x \ge 0
\\
0 & x<0
\end{array}
\right .
$$

​	Sigmoid函数的导数在大于10或者小于-10的地方的局部梯度都接近于0，不利于网路梯度的传递，在训练过程中可能会引起梯度反向传播时梯度消失。相比于Sigmoid函数，ReLU函数能让梯度流更加流畅，训练过程收敛更快。

### 卷积神经网络训练的预备工作

​	由于任务是二分类，所以训练使用交叉熵作为损失函数，使用随机梯度下降作为优化器，使用`DataLoader`加载数据集。通过对`DataLoader`的batch size的设置，实际上的优化算法应该等价于小批量梯度下降算法。

​	接下里进行对超参数的设置。

#### batch size的设置

​	先设置`DataLoader`的batch size，让学习率保持0.0001（较低的学习率可以保证网络很难达到过拟合，更方便观察batch size对网络训练过程的影响），batch size从32开始，每次加上32，观察网络的训练情况。

| batch size | 训练结果                                                     |
| ---------- | ------------------------------------------------------------ |
| 32         | ![test_accuracy](.\batchsize32\test_accuracy.svg)![train_accuracy](.\batchsize32\train_accuracy.svg) |
| 64         | ![test_accuracy](.\batchsize64\test_accuracy.svg)![train_accuracy](.\batchsize64\train_accuracy.svg) |
| 96         | ![test_accuracy](.\batchsize96\test_accuracy.svg)![train_accuracy](.\batchsize96\train_accuracy.svg) |
| 128        | ![test_accuracy](.\batchsize128\test_accuracy.svg)![train_accuracy](.\batchsize128\train_accuracy.svg) |
| 160        | ![test_accuracy](.\batchsize160\test_accuracy.svg)![train_accuracy](.\batchsize160\train_accuracy.svg) |
| 192        | ![test_accuracy](.\batchsize192\test_accuracy.svg)![train_accuracy](.\batchsize192\train_accuracy.svg) |
| 224        | ![test_accuracy](.\batchsize224\test_accuracy.svg)![train_accuracy](.\batchsize224\train_accuracy.svg) |
| 256        | ![test_accuracy](.\batchsize256\test_accuracy.svg)![train_accuracy](.\batchsize256\train_accuracy.svg) |

​	由于时间原因，每个batch size的实验只能进行一次，实验所得数据有很大的偶然性和不稳定性。但也能从这些数据中看出这样的趋势：batch size越大，小批量梯度下降算法就越不容易过拟合。当batch size较小时，即使学习率设置为0.0001，网络权值在训练到60轮左右的时候就会过拟合；而batch size增加后，300轮的训练也不能看到网络权值的过拟合。

​	查阅资料后得知，大的batch size有如下好处：

+ 提高内存利用率，增加矩阵乘法的并行效率。
+ 一次epoch中需要的迭代次数减少，加快处理速度。
+ 在一定范围内，batch size越大，它所确定的梯度下降方面就越准确，训练的振荡就越小。可以从上述数据中发现当batch size为32时，测试集的准确率在过拟合前就有振荡，而随batch size增大，准确率的振荡幅度越来越小。

​	但是batch size也不是越大越好的，盲目增大batch size会导致网络的训练容易过早陷入局部最优，泛化性较差。

​	因为我设置的epoch总计300轮，综合考虑过拟合与欠拟合后选择256作为batch size的值。

#### learning rate的设置

保持batch size为256，让learning rate从0.0001开始，每次增加0.0002，观察网络的训练情况。

### 卷积神经网络训练

​	卷积神经网络的训练环境为

> 硬件配置：
>
> | 名称  | 型号     |
> | ---- | ------------ |
> | CPU  | i7-9750H     |
> | GPU  | GTX1660ti 6g |
> | RAM  | 16G 2133MHz  |
>

> 软件环境：
>
> | 名称        | 版本            |
> | ----------- | --------------- |
> | 操作系统    | Windows10 2021H |
> | python      | 3.8.12          |
> | pytorch     | 1.10.0          |
> | tensorboard | 2.6.0           |
> | torchvision | 0.11.1          |
> | numpy       | 1.21.2          |
> | opencv      | 4.0.1           |

设置batch size为256，设置learning rate为0.0005，设置epoch为200。

重复10次训练，选择测试集上准确率大于80%的模型，然后将其放入写好的模块中的对应部分。

### 卷积神经网络的不足和可能的改进措施

#### 出现的问题

​	将训练得到卷积神经网络模型放到模块中并尝试运行，发现如下两个问题：

+ 只有当人脸出现在摄像机中间位置并距离摄像机较近网络才能识别到有人出现。
+ 当人脸倾斜超过一定的角度后网络会识别不出有人出现。
+ 当人静止在摄像机前，即保证输入的图像基本不变时，网络会一会儿输出有人出现，一会输出没有人。

#### 问题产生的原因

​	对上述问题分析后，大致确定如下几个可能导致这些问题的原因：

+ 数据集不够强，所有的人脸图像几乎都是正朝相机且占据图像的大部分区域，人脸基本没有倾斜或者只占图像一小部分的情况。这导致网络学习到的都是类似这样的图像的模板，所以会出现第一二点问题。
+ 网络的边界依然不够明显，虽然已经使用交叉熵而非MSE作为损失函数，但是依然不能很好的区分开部分在边界附近的图像

#### 可能的解决方法

​	经过思考，我认为有如下几种解决方法：

+ 在实际使用中，对输入的图像划分出可能有人脸的候选区域，将这些候选区域输入网络中，然后观察网络的输出中是否有有人出现，若有，则说明有人出现；若全为false，则说明这张图像中没有人脸出现。

  但这种方法也存在问题，例如如何划分出候选区域，如何保证候选区域中一定包括目标人脸。

  结合所学并查阅相关资料后总结了如下几个获取候选区域的方法：

  1. 滑动窗口

     滑动窗口即暴力搜索每个大小每个地方的可能区域，实际上就是暴力搜索。

     这种方法效率太低，不予考虑。

  2. 选择运动的区域

     借鉴数字图像处理中的方法，选择视频相邻两帧之间的图像变化区域作为候选区域，把梯度方向、强度相似且位置相邻的区域作为同一个候选区域。

     我认为可行，但问题是可能存在摄像机晃动的情况，此时整个图像都将作为候选区域，这会导致错误的结果。
     
  3. 使用聚类算法

     使用k-means或者谱聚类把相似且位置相邻的区域作为一个候选区域。

+ 可以尝试使用自适应梯度法去训练，同时增加训练的epoch次数，让网络的边界更明晰。

  但是更过的epoch次数可能让网络训练到一定次数后过拟合，之后的训练都是无效训练。可以尝试在网络中添加随机失活层来让网络不那么快过拟合。

## 假设检验

由于网络的结果存在和真实情况之间存在误差，所以希望借助假设检验的办法来减小误差。通过记录前6次网络输出的结果，把这些结果作为样本进行假设检验。

由于假设检验过于复杂，此处采用简化的统计方法，只要这6次中网络认为有人出现的次数大于等于5次，那么就认为此时有人；相反，只要这6次中网络认为没有有人的次数大于等于5次，那么就认为此时没有人。